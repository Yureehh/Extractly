"""
Batch Extraction â€“ multi-doc classification, OCR, extraction & correction UI.
"""

from __future__ import annotations
import contextlib
import io
import json
from datetime import datetime, timezone
import streamlit as st
import pandas as pd

from src.ocr_engine import run_ocr
from utils.preprocess import preprocess
from src.schema_manager import SchemaManager
from src.classifier import classify
from src.extractor import extract
from utils.ui_components import inject_logo, inject_common_styles
from utils.utils import (
    generate_doc_id,
    load_feedback,
    upsert_feedback,
    diff_fields,
)

# â”€â”€â”€â”€â”€ page & globals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config("Extraction", page_icon="ğŸ”", layout="wide")
st.title("ğŸ” Extraction")
schema_mgr = SchemaManager()

inject_logo("data/assets/data_reply.svg", height="80px")  # Adjust height as needed
inject_common_styles()

# â”€â”€â”€â”€â”€ CSS for image hover zoom â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown(
    """
<style>
img:hover { transform:scale(2.5); transition:0.15s ease-in-out;
            z-index:1000; position:relative }
</style>
""",
    unsafe_allow_html=True,
)

# â”€â”€â”€â”€â”€ sidebar: settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸  Options")
    run_ocr_checkbox = st.checkbox("Run OCR first", value=False)
    calc_conf = st.checkbox("Compute confidences", value=False)
    conf_threshold = st.slider(
        "Confidence threshold (%)",
        0,
        100,
        70,
        help="Documents below this confidence will be flagged",
    )

    ocr_engine = st.selectbox(
        "OCR engine",
        ["LLM-OCR", "Tesseract"],
        disabled=not run_ocr_checkbox,
        key="sel_engine",
    )

    # NEW: System Prompts Section
    st.header("ğŸ¤– System Prompts")

    # Default prompts
    DEFAULT_CLASSIFIER_PROMPT = "You are a document classifier."
    DEFAULT_EXTRACTOR_PROMPT = "You are a metadata-extraction assistant.\nReturn only JSON with keys metadata, snippets, confidence."

    with st.expander("ğŸ“ Edit Prompts", expanded=False):
        st.subheader("Classification Prompt")
        classifier_prompt = st.text_area(
            "System prompt for document classification:",
            value=st.session_state.get("classifier_prompt", DEFAULT_CLASSIFIER_PROMPT),
            height=100,
            help="This prompt guides how the AI classifies document types",
            key="classifier_prompt_input",
        )

        st.subheader("Extraction Prompt")
        extractor_prompt = st.text_area(
            "System prompt for metadata extraction:",
            value=st.session_state.get("extractor_prompt", DEFAULT_EXTRACTOR_PROMPT),
            height=150,
            help="This prompt guides how the AI extracts metadata fields",
            key="extractor_prompt_input",
        )

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ’¾ Save Prompts"):
                st.session_state["classifier_prompt"] = classifier_prompt
                st.session_state["extractor_prompt"] = extractor_prompt
                st.success("Prompts saved!")

        with col2:
            if st.button("ğŸ”„ Reset to Default"):
                st.session_state["classifier_prompt"] = DEFAULT_CLASSIFIER_PROMPT
                st.session_state["extractor_prompt"] = DEFAULT_EXTRACTOR_PROMPT
                st.rerun()

    # âœ‚ï¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  OCR-preview toggle  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€âœ‚ï¸
    if run_ocr_checkbox and "ocr_map" in st.session_state:
        with st.sidebar.expander("ğŸ” Preview raw OCR text", expanded=False):
            for name, ocr_txt in st.session_state["ocr_map"].items():
                st.markdown(f"**{name}**")
                st.text_area(
                    label=" ",
                    value=ocr_txt[:10_000],
                    height=200,
                    key=f"ocr_{name}",
                    label_visibility="collapsed",
                )

# â”€â”€â”€â”€â”€ file uploader â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
files = st.file_uploader(
    "Upload PDFs or images",
    type=["pdf", "png", "jpg", "jpeg"],
    accept_multiple_files=True,
)

if not files:
    st.info("Awaiting uploads â€¦")
    st.stop()

# â”€â”€â”€â”€â”€ load past corrections by filename â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
past = load_feedback()
corrected_map = {}
past_metadata_map = {}
for r in past:
    if r.get("file_name"):
        corrected_map[r["file_name"]] = r["doc_type"]
        if r.get("metadata_corrected") and r["metadata_corrected"] != "{}":
            with contextlib.suppress(json.JSONDecodeError):
                past_metadata_map[r["file_name"]] = json.loads(r["metadata_corrected"])

# â”€â”€â”€â”€â”€ ensure session state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.session_state.setdefault("doc_rows", [])
st.session_state.setdefault("extracted", False)
doc_rows: list[dict] = st.session_state["doc_rows"]

# â”€â”€â”€â”€â”€ run buttons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
c1, c2, c3 = st.columns(3)
seq_clicked = c1.button("ğŸš€ Classify & Extract", use_container_width=True)
classify_clicked = c2.button("â–¶ï¸ Classify Only", use_container_width=True)
extract_clicked = c3.button(
    "âš¡ Extract All", disabled=not doc_rows, use_container_width=True
)

if st.button("ğŸ”„ Start over (keep uploads)", key="reset_all", type="secondary"):
    for k in ("doc_rows", "extracted", "ocr_map", "ocr_preview"):
        st.session_state.pop(k, None)
    st.toast("Workspace cleared â€“ you can run the pipeline again.", icon="ğŸ”„")
    st.rerun()

st.markdown("<hr>", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€ 1ï¸âƒ£ on-click: build doc_rows â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if classify_clicked or seq_clicked:
    st.session_state["extracted"] = False
    st.session_state["ocr_preview"] = ""
    st.session_state["doc_rows"] = []
    prog = st.progress(0.0, "Classifyingâ€¦")
    cls_results = []

    # CHANGE: Add Unknown/Other to classification candidates
    classification_candidates = schema_mgr.get_types() + ["Unknown", "Other"]

    for i, up in enumerate(files, start=1):
        images = preprocess(up)
        fname = up.name
        doc_id = generate_doc_id(up) or f"id_{i}"
        ocr_txt = ""

        if run_ocr_checkbox:
            ocr_engine_name = "Paddle" if ocr_engine == "LLM-OCR" else "Tesseract"
            ocr_txt = run_ocr(images, ocr_engine_name)
            st.session_state.setdefault("ocr_map", {})
            st.session_state["ocr_map"][fname] = ocr_txt
            if (
                "ocr_preview" in st.session_state
                and not st.session_state["ocr_preview"]
            ):
                st.session_state["ocr_preview"] = ocr_txt

        with io.BytesIO() as buf:
            img = images[0].copy()
            img.thumbnail((140, 140))
            img.save(buf, format="PNG")
            thumb = buf.getvalue()

        # ---------- build rows with enhanced classification -------------------------
        if fname in corrected_map:
            doc_type = corrected_map[fname]
            confidence = None
            reasoning = "retrieved from past correction"
        else:
            cls_resp = classify(
                images,
                classification_candidates,
                use_confidence=calc_conf,
                n_votes=5,
                system_prompt=st.session_state.get(
                    "classifier_prompt"
                ),  # Add this line
            )
            doc_type = cls_resp["doc_type"]
            confidence = cls_resp.get("confidence")
            reasoning = cls_resp.get("reasoning", "")

        cls_results.append(
            {
                "file_name": fname,
                "doc_id": doc_id,
                "thumb": thumb,
                "images": images,
                "detected": doc_type,
                "final_type": doc_type,
                "reasoning": reasoning,
                "fields": None,
                "fields_corrected": None,
                "confidence": confidence,
            }
        )
        prog.progress(i / len(files), f"Classifying: {fname}")

    st.session_state["doc_rows"] = cls_results
    doc_rows = st.session_state["doc_rows"]
    st.toast("Classification finished â€“ adjust below if needed.", icon="âœ…")
    if not seq_clicked:
        st.rerun()

# â”€â”€â”€â”€â”€ 2ï¸âƒ£ render classification review â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if doc_rows and not st.session_state.get("extracted"):
    st.subheader("ğŸ“‘ Review detected document types")

    for idx, row in enumerate(doc_rows):
        # CHANGE: Enhanced confidence display and unrecognized document handling
        conf_pct = int(row.get("confidence", 0) * 100) if row.get("confidence") else 0
        is_unrecognized = row["final_type"] in ["Unknown", "Other"]
        is_low_confidence = conf_pct < conf_threshold

        # Color-coded title based on status
        if is_unrecognized or is_low_confidence:
            status_emoji = "âš ï¸"
            title_color = "ğŸ”´"
        else:
            status_emoji = "âœ…"
            title_color = "ğŸŸ¢"

        with st.expander(
            f"{status_emoji} {row['file_name']} â€” {row['final_type']} {title_color} {conf_pct}%",
            expanded=is_unrecognized
            or is_low_confidence,  # Auto-expand problematic ones
        ):
            col1, col2, col3 = st.columns([1, 2, 1])

            with col1:
                st.image(row["thumb"], width=140)

            with col2:
                # CHANGE: Enhanced type selection with Unknown/Other
                choices = schema_mgr.get_types() + ["Unknown", "Other"]
                if row["final_type"] not in choices:
                    choices.insert(0, row["final_type"])

                sel = st.selectbox(
                    "Document type",
                    choices,
                    index=choices.index(row["final_type"]),
                    key=f"type_{row['doc_id']}",
                )
                st.session_state["doc_rows"][idx]["final_type"] = sel

                # Enhanced status display
                if is_unrecognized:
                    st.error("âŒ Unrecognized document type")
                elif is_low_confidence:
                    st.warning(f"âš ï¸ Low confidence ({conf_pct}% < {conf_threshold}%)")

            with col3:
                # CHANGE: Enhanced confidence display in %
                if calc_conf and row.get("confidence") is not None:
                    if conf_pct >= 80:
                        st.success(f"ğŸŸ¢ {conf_pct}%")
                    elif conf_pct >= 60:
                        st.warning(f"ğŸŸ¡ {conf_pct}%")
                    else:
                        st.error(f"ğŸ”´ {conf_pct}%")

                    st.caption(f"Threshold: {conf_threshold}%")

    if st.button("ğŸ’¾ Save type corrections"):
        for row in doc_rows:
            upsert_feedback(
                {
                    "doc_id": row["doc_id"],
                    "file_name": row["file_name"],
                    "doc_type": row["final_type"],
                    "metadata_extracted": "{}",
                    "metadata_corrected": "{}",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                }
            )
        st.toast("Document types saved ğŸ‘", icon="ğŸ’¾")

st.markdown("<br><br>", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€ 3ï¸âƒ£ ON-CLICK: run extraction with unrecognized document handling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if (extract_clicked or seq_clicked) and not st.session_state.get("extracted"):
    st.subheader("ğŸ“¦ Extracting Data...")
    prog = st.progress(0.0, "Extractingâ€¦")

    for i, row in enumerate(doc_rows, start=1):
        if "cancel_extraction" in st.session_state:
            break

        # CHANGE: Skip extraction for unrecognized documents
        if row["final_type"] in ["Unknown", "Other"]:
            st.session_state["doc_rows"][i - 1]["fields"] = {}
            st.session_state["doc_rows"][i - 1]["field_conf"] = {}
            st.session_state["doc_rows"][i - 1]["fields_corrected"] = {}
            prog.progress(
                i / len(doc_rows), f"Skipping unrecognized: {row['file_name']}"
            )
            continue

        schema = schema_mgr.get(row["final_type"]) or []
        if not schema:
            st.session_state["doc_rows"][i - 1]["fields"] = {}
            st.session_state["doc_rows"][i - 1]["field_conf"] = {}
            st.session_state["doc_rows"][i - 1]["fields_corrected"] = {}
            continue

        ocr_txt = None
        if run_ocr_checkbox:
            engine_name = "Paddle" if ocr_engine == "LLM-OCR" else "Tesseract"
            ocr_txt = run_ocr(row["images"], engine_name)

        out = extract(
            row["images"],
            schema,
            ocr_text=ocr_txt,
            with_confidence=calc_conf,
            system_prompt=st.session_state.get("extractor_prompt"),  # Add this line
        ) or {"metadata": {}, "confidence": {}}

        if not any(out["metadata"].values()):
            st.toast(f"No fields detected in {row['file_name']}", icon="âš ï¸")

        st.session_state["doc_rows"][i - 1]["fields"] = out["metadata"]
        st.session_state["doc_rows"][i - 1]["field_conf"] = out.get("confidence", {})

        file_name = row["file_name"]
        if file_name in past_metadata_map:
            st.session_state["doc_rows"][i - 1]["fields_corrected"] = past_metadata_map[
                file_name
            ]
        else:
            st.session_state["doc_rows"][i - 1]["fields_corrected"] = out[
                "metadata"
            ].copy()

        prog.progress(i / len(doc_rows), f"Extracting from: {row['file_name']}")

    if st.session_state.get("extracted") is False:
        st.button("ğŸ›‘ Cancel extraction", key="cancel_extraction")

    st.session_state["extracted"] = True
    extract_clicked = False
    seq_clicked = False
    st.toast("Extraction completed â€“ review below", icon="ğŸ“¦")
    st.rerun()

# â”€â”€â”€â”€â”€ 4ï¸âƒ£ RENDER: extraction review & correction UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.get("extracted"):
    st.subheader("ğŸ“¦ Review and Correct Extracted Data")

    for i, row in enumerate(doc_rows):
        # CHANGE: Handle unrecognized documents in review
        if row["final_type"] in ["Unknown", "Other"]:
            with st.expander(
                f"âš ï¸ {row['file_name']} â€” {row['final_type']} (SKIPPED)", expanded=False
            ):
                st.warning(
                    "This document was skipped because it's unrecognized. Please reclassify it first."
                )
                continue

        with st.expander(f"{row['file_name']} â€” {row['final_type']}", expanded=True):
            if not row.get("fields_corrected"):
                st.warning("No fields were extracted or loaded for this document type.")
                continue

            # CHANGE: Enhanced confidence display in data editor (% format)
            row_conf = row.get("field_conf", {})
            # Convert confidence to percentage format
            conf_display = {}
            for k, v in row_conf.items():
                if isinstance(v, (int, float)):
                    conf_display[k] = f"{int(v * 100)}%"
                else:
                    conf_display[k] = str(v) if v else ""

            df = pd.DataFrame(
                {
                    "Field": list(row["fields_corrected"].keys()),
                    "Value": list(row["fields_corrected"].values()),
                    "Conf.": [
                        conf_display.get(k, "") for k in row["fields_corrected"]
                    ],  # CHANGE: Show %
                }
            )

            edited_df = st.data_editor(
                df,
                key=f"grid_{row['doc_id']}",
                disabled=["Field", "Conf."],
                use_container_width=True,
            )

            updated_values = pd.Series(
                edited_df.Value.values, index=edited_df.Field
            ).to_dict()

            st.session_state["doc_rows"][i]["fields_corrected"] = updated_values

            # â”€â”€ enhanced action buttons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            col_re, col_save, col_download = st.columns([0.08, 0.08, 0.08])

            with col_re:
                if st.button("â†» Re-extract", key=f"reextract_{row['doc_id']}"):
                    schema = schema_mgr.get(row["final_type"]) or []
                    ocr_txt = (
                        st.session_state.get("ocr_map", {}).get(row["file_name"])
                        if run_ocr_checkbox
                        else None
                    )
                    new_out = extract(
                        row["images"],
                        schema,
                        ocr_text=ocr_txt,
                        with_confidence=calc_conf,
                        system_prompt=st.session_state.get(
                            "extractor_prompt"
                        ),  # Add this line
                    ) or {"metadata": {}, "confidence": {}}

                    row["fields"] = new_out["metadata"]
                    row["field_conf"] = new_out.get("confidence", {})
                    row["fields_corrected"] = new_out["metadata"].copy()
                    st.toast(f"Re-extracted {row['file_name']}", icon="âœ…")
                    st.rerun()

            with col_save:
                if st.button("ğŸ’¾ Save", key=f"save_{row['doc_id']}"):
                    current_row = st.session_state["doc_rows"][i]
                    changed = diff_fields(
                        current_row["fields"], current_row["fields_corrected"]
                    )
                    upsert_feedback(
                        {
                            "doc_id": current_row["doc_id"],
                            "file_name": current_row["file_name"],
                            "doc_type": current_row["final_type"],
                            "metadata_extracted": json.dumps(
                                current_row["fields"], ensure_ascii=False
                            ),
                            "metadata_corrected": json.dumps(
                                current_row["fields_corrected"], ensure_ascii=False
                            ),
                            "fields_corrected": changed,
                            "timestamp": datetime.now(timezone.utc).isoformat(),
                        }
                    )
                    st.toast(f"Saved {current_row['file_name']}", icon="ğŸ’¾")

            # NEW: Individual download button
            with col_download:
                if st.button("ğŸ“„ JSON", key=f"download_{row['doc_id']}"):
                    # Fix: Handle None confidence properly
                    confidence_val = row.get("confidence")
                    if confidence_val is not None:
                        confidence_display = f"{int(confidence_val * 100)}%"
                    else:
                        confidence_display = "N/A"

                    result = {
                        "document_info": {
                            "filename": row["file_name"],
                            "document_type": row["final_type"],
                            "confidence": confidence_display,  # Fixed
                            "timestamp": datetime.now().isoformat(),
                        },
                        "original_extraction": row.get("fields", {}),
                        "corrected_metadata": row.get("fields_corrected", {}),
                        "confidence_scores": {
                            k: f"{int(v * 100)}%"
                            for k, v in row.get("field_conf", {}).items()
                            if isinstance(v, (int, float))
                            and v is not None  # Added None check
                        },
                        "processing_info": {
                            "ocr_used": run_ocr_checkbox,
                            "ocr_engine": ocr_engine if run_ocr_checkbox else "none",
                            "confidence_threshold": f"{conf_threshold}%",
                        },
                    }

    # Enhanced bulk save with session summary
    col1, col2 = st.columns([3, 1])
    with col1:
        if st.button(
            "ğŸ’¾ Save all corrections", use_container_width=True, type="primary"
        ):
            saved_count = 0
            for row in st.session_state["doc_rows"]:
                if row["final_type"] not in ["Unknown", "Other"]:
                    upsert_feedback(
                        {
                            "doc_id": row["doc_id"],
                            "file_name": row["file_name"],
                            "doc_type": row["final_type"],
                            "metadata_extracted": json.dumps(
                                row["fields"], ensure_ascii=False
                            ),
                            "metadata_corrected": json.dumps(
                                row["fields_corrected"], ensure_ascii=False
                            ),
                            "timestamp": datetime.now(timezone.utc).isoformat(),
                        }
                    )
                    saved_count += 1
            st.toast(f"Saved {saved_count} documents â€“ thank you!", icon="ğŸ’¾")

    with col2:
        # NEW: Bulk download button
        if st.button("ğŸ“¥ Download All JSON", use_container_width=True):
            # Prepare bulk export
            bulk_results = {
                "export_info": {
                    "timestamp": datetime.now().isoformat(),
                    "total_documents": len(doc_rows),
                    "processed_documents": len(
                        [
                            r
                            for r in doc_rows
                            if r["final_type"] not in ["Unknown", "Other"]
                        ]
                    ),
                    "confidence_threshold": f"{conf_threshold}%",
                },
                "documents": [],
            }

            for row in doc_rows:
                confidence_val = row.get("confidence")
                if confidence_val is not None:
                    confidence_display = f"{int(confidence_val * 100)}%"
                else:
                    confidence_display = "N/A"

                doc_result = {
                    "filename": row["file_name"],
                    "document_type": row["final_type"],
                    "confidence": confidence_display,  # Fixed
                    "original_extraction": row.get("fields", {}),
                    "corrected_metadata": row.get("fields_corrected", {}),
                    "confidence_scores": {
                        k: f"{int(v * 100)}%"
                        for k, v in row.get("field_conf", {}).items()
                        if isinstance(v, (int, float))
                        and v is not None  # Added None check
                    },
                }
                bulk_results["documents"].append(doc_result)

            json_str = json.dumps(bulk_results, indent=2, ensure_ascii=False)
            st.download_button(
                label="ğŸ“„ Download Complete Session",
                data=json_str,
                file_name=f"bulk_extraction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                key="bulk_download",
            )
